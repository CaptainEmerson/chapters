# What to Do When Your Data Tells You There Is Something Wrong with the Universe_Nenad Medvidovic_, University of Southern Calofornia
<br>
_Alessandro Orso_, Georgia Institute of Technology

## Prologue

In “Remember Me”, an episode of Star Trek: The Next Generation, Dr. Beverly Crusher does not realize that she has ended up inside a spacetime disturbance.  After a series of unexpected and, to her, unexplainable events, she tries to calm herself and assess her situation in order to find a way out of it.  Thinking back over what has transpired, Dr. Crusher states: “If there's nothing wrong with me, maybe there's something wrong with the universe!”
This is an extreme conclusion, and in this instance obviously the wrong one.  Yet, the scientist, frustrated by her inability to understand the observations she had made inside the spacetime disturbance—i.e., the data she had personally collected “with her own eyes and ears”, with her handheld tricorder, and via the countless sensors on the Starship Enterprise—actually considered it.  Fortunately, the episode had to be concluded in 45 minutes and, as always, one of the main characters had to be saved.  Otherwise, Dr. Crusher may still be trying to resolve her predicament based on incomplete data, lack of awareness of the precipitating event, and analysis of the available data from the wrong perspective: she was unaware that she got pulled into the spacetime disturbance and that, in the world of Star Trek at least, the usual laws of physics did not apply there.How does this relate to the problem of Big Data in software engineering?  Very closely, actually!  First, we are practitioners of a “science of the artificial”, meaning that we cannot rely on laws of physics or their analogs in understanding the phenomena we are studying. Second, very often, we do not understand the precipitating events for the phenomena in which we are interested, either because that data was never recorded or because nobody actually realized at the time that they had encountered something important.  Third, despite the seemingly huge amounts of data we can now collect about a system, the humans who built it, and the project from which it resulted, by definition that data is incomplete; we are often looking for “second-order events” because the actual phenomena we are interested in have not been recorded or are altogether unobservable.  Finally, we bring our biases to the processes of data collection and analysis.  In other words, we (consciously or otherwise) select the perspectives from which we collect and analyze the data, and those perspectives inevitably color our conclusions.
The rest of the chapter would elaborate on different classes of conclusions drawn from data:1.	Simply incorrect
2. Only partially correct – with the resulting danger of acting on it3.	Correct but obvious – in other words, waste of everyone’s time4.	Correct, non-obvious, but not usable in a practical setting5.	Correct, non-earth-shattering, but relatively useful6.	Correct, obvious, earth-shattering consequences, clearly actionableI’d argue that there is sort-of a bell curve from 1 to 6, where most of the existing “big data SE” research falls in categories 3 and 4, a few more in 2 and 5, and some outliers in 1 and 6.  I would also make the argument that 1, in particular, can be useful to those studying this area because it would allow us to avoid repeating the same mistakes.